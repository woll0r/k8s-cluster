{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"K8S-GitOps","text":"<p>Warning</p> <p>These docs haven't been touched in a while, so they might be out of date.</p> <p>This repository serves as the declarative \"source of truth\" for my Kubernetes cluster at home. Flux watches over the <code>cluster</code> folder to check for changes and apply them to the cluster.</p> <p>The flux-cluster-template repository served as a loose base for things.</p>"},{"location":"bootstrap/","title":"Bootstrap","text":"<p>Refactoring is in progress!</p> <p>Stuff in this document is not going to work anymore, at least not for now.</p>"},{"location":"bootstrap/#create-an-age-key","title":"Create an age key","text":"<pre><code>age-keygen -o age.agekey\n</code></pre>"},{"location":"bootstrap/#verify-if-the-cluster-is-ready-for-flux","title":"Verify if the cluster is ready for Flux","text":"<pre><code>flux check --pre\n</code></pre>"},{"location":"bootstrap/#create-the-flux-system-namespace","title":"Create the <code>flux-system</code> namespace","text":"<pre><code>kubectl create namespace flux-system\n</code></pre>"},{"location":"bootstrap/#add-the-age-key-for-decrypting-secrets","title":"Add the AGE key for decrypting secrets","text":"<pre><code>cat age.agekey |\nkubectl -n flux-system create secret generic sops-age \\\n--from-file=age.agekey=/dev/stdin\n</code></pre>"},{"location":"bootstrap/#install-flux","title":"Install Flux","text":"<p>Warning</p> <p>You should run this command twice because there are race conditions on the Flux CRDs. The second run should work without errors.</p> <pre><code>kubectl apply --kustomize=./cluster/base/flux-system\n</code></pre> <p>At this point, Flux should start reconciling the cluster into the desired state.</p>"},{"location":"overview/","title":"Detailed overview","text":""},{"location":"overview/#cluster-setup","title":"Cluster setup","text":"<p>The cluster runs k3s on top of Ubuntu 21.04 using the Ansible role from ansible-role-k3s. It runs semi-hyperconverged, with storage and workloads sharing machines and NFS on a NAS for larger files.</p>"},{"location":"overview/#components","title":"Components","text":"<ul> <li>Calico: for internal networking for the cluster using BGP.</li> <li>Rook: Persistent volumes using Ceph RBD storage.</li> <li>Mozilla SOPS: Encryption of secrets.</li> <li>external-dns: Create DNS entries in Cloudflare DNS for access through a Cloudflare tunnel.</li> <li>cert-manager: Provides the TLS certificates for the ingresses.</li> <li>kube-vip: HA for the control plane, inside the cluster.</li> </ul>"},{"location":"overview/#structure","title":"Structure","text":"<p>Under the <code>cluster</code> directory, the following structure is present for flux to apply:</p> <ul> <li>base is the entrypoint for Flux</li> <li>apps contains the applications that run inside the cluster</li> </ul>"},{"location":"overview/#automation","title":"Automation","text":"<ul> <li>Github actions check for code formatting, build docs and some other very important background tasks on Git changes.</li> <li>System Upgrade Controller will automatically update k3s.</li> <li>Kured automatically reboots the nodes whenever reboots are required for OS updates.</li> <li>Renovate will automatically open pull requests for new versions of Helm charts and container images.</li> </ul>"},{"location":"rook/","title":"Rook","text":""},{"location":"rook/#directly-interacting-with-the-ceph-cluster","title":"Directly interacting with the Ceph cluster","text":"<p>Open up a shell in the <code>rook-ceph-direct-mount</code> pod.</p> <pre><code>kubectl exec -it -n rook-ceph rook-direct-mount-5fd4b8d8c5-8sd9q -- bash\n</code></pre> <p>In this shell, all Ceph commands can be executed.</p>"},{"location":"rook/#directly-mounting-a-volume","title":"Directly mounting a volume","text":"<p>First, suspend the HelmRelease and scale down the deployment so the storage is not in use.</p> <pre><code>flux suspend helmrelease -n media bazarr\nkubectl scale deployment -n media bazarr --replicas 0\n</code></pre> <p>Next step is extracting the <code>csi-vol-*</code> string from the PersistentVolume.</p> <pre><code>kubectl get pv/$(kubectl get pv | grep bazarr-config \\\n    | awk -F' ' '{print $1}') -n home -o json \\\n    | jq -r '.spec.csi.volumeAttributes.imageName'\n</code></pre> <p>After this, connect to the <code>rook-ceph-direct-mount</code> pod, create a mount path and map the volume.</p> <pre><code>mkdir -p /mnt/data\nrbd map -p replicapool csi-vol-d72a57f3-1370-11ec-aa8b-babccd65caf2 \\\n    | xargs -I{} mount {} /mnt/data\n</code></pre> <p>Afterwards, unmount and unmap the volume.</p> <pre><code>umount /mnt/data\nrbd unmap -p replicapool csi-vol-d72a57f3-1370-11ec-aa8b-babccd65caf2\n</code></pre>"},{"location":"rook/#correcting-cluster-health-issues","title":"Correcting cluster health issues","text":"<p>Whenever a health issue occurs, usually the solution and/or troubleshooting steps can be found in the Ceph docs.</p>"}]}